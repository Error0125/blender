import torch
device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
#import models
import numpy as np
import os
#os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID" 
#os.environ["CUDA_VISIBLE_DEVICES"]= "3"

#model
import torch.nn as nn

MAXEPOCH=100
BATCH=1

class CNN(nn.Module):
    def __init__(self, nlayer=4, dropout=0.1): #ë“œë¡­ì•„ì›ƒì˜ ë¹„ìœ¨ì„ ëœë¤ìœ¼ë¡œ 0.1ë¡œ í•¨. í•™ìŠµì‹œì—ë§Œ ì‚¬ìš©í•˜ê³  ì˜ˆì¸¡ì‹œì—” ì‚¬ìš©í•˜ì§€ x
        super().__init__()
        layers = []

        drop = torch.nn.Dropout(p=dropout)
        conv1 = torch.nn.Conv1d(20,32,3,padding=1) # aa1hot,channel,
        layers = [drop,conv1]

        for k in range(nlayer):
            conv2 = torch.nn.Conv1d(32,32,3,padding=1) # aa1hot,channel,
            layers.append(conv2)
            layers.append(nn.BatchNorm1d(32)) #reluë³´ë‹¤ ë” ì¢‹ì€ê²Œ ì •ê·œí™”í•˜ëŠ” ê²ƒ. ì •ê·œí™”í•œ ê°’ì„ í™œì„±í•¨ìˆ˜ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë„£ê³ , ìµœì¢… ì¶œë ¥ê°’ì„ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë„£ëŠ”ë‹¤. ìì„¸í•œê±´ ë©”ëª¨ì¥
            layers.append(nn.ReLU(inplace=True)) #í™œì„±í™” í•¨ìˆ˜. max(0,input) (linear                                    ë³€í™˜ í›„ ë¹„ì„ í˜•ì„± ë„ì…í•´ì„œ ì‹ ê²½ë§ ë³µì¡ì„±                                     ì¶”ê°€.
                                                 #inplace : ë”ì´ìƒ ì¶”ê°€ ë©”ëª¨ë¦¬ ì†Œë¹„í•˜
                                                 #ì§€ ì•Šê³  ëŒë¦¬ê¸°
                                                 #gradient vanishing/exploding
                                                 #ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ 1

        self.layers = nn.ModuleList(layers)#íŒŒì´í† ì¹˜ì—ê²Œ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“ˆì´ ì €ì¥ë˜ì–´ìˆìŒì„ ì•Œë ¤ì£¼ê¸° ìœ„í•´ nn.modulistë¡œ ë‹¤ì‹œ ë˜í•‘í•´ì£¼ëŠ” ê³¼ì •.
        # 1 x 32 x nres
        self.outlayer = nn.Linear(32,3)

    def forward(self, seq):
        #pred = seq # should B x 20 x nres
        for layer in self.layers:
            seq = layer(seq)

        seq = torch.transpose(seq,1,2) # put channel at the last

        pred = self.outlayer(seq)
        pred = torch.transpose(pred,2,1)
        return pred

class DataSet(torch.utils.data.Dataset): #ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹. ë°˜ë“œì‹œ 3ê°€ì§€ í¬í•¨í• ê²ƒ!
    def __init__(self, datalist):
        super().__init__()
        self.tags = datalist

    def __len__(self):
        return len(self.tags) #ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜

    def __getitem__(self,index): #ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°ì´í„°ì…‹ì—ì„œ ë¶ˆëŸ¬ì˜¤ê³  ë³€í˜•ê±°ì³ ë°˜í™˜.
        npz = '/Users/oyujeong/Desktop/blender/sss_struct/'+ self.tags[index]
        
        data = np.load(npz,allow_pickle=True) #trueë¡œ ì•ˆí•´ì£¼ë©´ íŒŒì¼ì´ ë¡œë“œ ì•ˆë  ìˆ˜ë„ ìˆìŒ.

        aas = 'ACDEFGHIKLMNPQRSTVWY' 
        SS3 = 'HEC'

        #print('ğŸ˜‹hello')

        seqs = [aas.index(a) for a in data['seq'].tolist()]
        #print(f'seqs: {seqs}')
        SSs  = [SS3.index(a) for a in data['SS'].tolist()]
        #print(f'SSs: {SSs}')
        seq1hot = np.transpose(np.eye(20)[seqs],(1,0)) # 20xnres
        #SS1hot = np.transpose(np.eye(3)[SSs],(1,0))
        #print('!!!!!!!!!!')
        #print(seq1hot.shape[1])

    

        return seq1hot, SSs, seq1hot.shape[1]

def collate(samples):
    try:
        seq,SS,nres = map(list, zip(*samples))
        #print(f'what is seq: {seq}')
        #print(f'what is SS: {SS}')
        nres = max(nres)
        #print(f'maxnres: {nres}')
        B = len(seq)
        #print(f'b: {B}')

        # map into maxres
        seqs = torch.zeros(B,20,nres)
        SSs  = torch.zeros(B,nres,dtype=torch.long)
        for i,s in enumerate(seq):
            #print(f'seqs: {seqs}')
            #print(seqs[i,:,:len(s[1])]
            seqs[i,:,:len(s[1])] = torch.tensor(s)
        for i,s in enumerate(SS):
            #print(f'SSs: {SSs}')
            #print(f'ss[i]: {SS[i]}')
            #print(f'ss[i][:3]: {SS[i][:3]}')
            SSs[i][:len(s)] = torch.tensor(s)

        #print(f'seqs: {seqs}')
        #print(f'SSs: {SSs}')

    except:
        print("collate fail")
        return False, False

    return seqs, SSs

model = CNN()
model.to(device) #cnn ëª¨ë¸ì„ gpuë¡œ ì´ë™.

## load dataset
trainlist = np.load('/Users/oyujeong/Desktop/blender/train.npy')
validlist = np.load('/Users/oyujeong/Desktop/blender/valid.npy')

trainset = DataSet(trainlist)
validset = DataSet(validlist)

generator_params = {
    'shuffle': False, #ëª¨ë“  ë°°ì¹˜ ìˆœíšŒ í›„ ë°ì´í„°ì…‹ì˜ ì…”í”Œ ì—¬ë¶€
    'num_workers': 0, #ì°¸ì—¬ì‹œí‚¬ cpu ì½”ì–´ ê°œìˆ˜. (multi-loader, íŠœë‹ì„ í†µí•´ ì†ë„ê°€ ìµœëŒ€í•œ
                      #ì•ˆëŠë ¤ì§€ëŠ” ì„ ì—ì„œ ì¡°ì ˆ ê°€ëŠ¥. default = 0)
    'pin_memory': True, #íŠ¸ë£¨ì˜ ê²½ìš°, í…ì„œë¥¼ cuda ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼. ì¦‰, cpuì—ì„œ ëŒì•„ê°€ë˜ ë°ì´í„°ì…‹ì„
                        #gpuë¡œ ì˜®ê²¨ì„œ ê³„ì‚°ì„ ì§„í–‰í•˜ë„ë¡ í•œë‹¤.
    'collate_fn': collate, #ë°ì´í„° ì‚¬ì´ì¦ˆë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì‚¬ìš©.?
    'batch_size': BATCH,
    'worker_init_fn' : np.random.seed() #ì–´ë–¤ workerë¥¼ ë¶ˆëŸ¬ì˜¬ê²ƒì¸ê°€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
                                        #np.random.seed()ëŠ” ê´„í˜¸ì•ˆì˜ ìˆ«ìë¥¼ ì‹œì‘ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‚œìˆ˜ë¥¼ í˜•ì„±í•˜ëŠ” ê²ƒ. ì‹œì‘ ìˆ«ìë¥¼ ê³ ì •í•œë‹¤!
                                            #ê³ ì • ìˆ«ìê°€ ë™ì¼í•˜ë©´ ìƒì„±ë˜ëŠ” ë‚œìˆ˜ë„ ë™ì¼í•¨. (íŒ¨í„´ì´ ë™ì¼í•˜ë‹ˆê¹Œ)
}
train_generator = torch.utils.data.DataLoader(trainset, **generator_params)
valid_generator = torch.utils.data.DataLoader(validset, **generator_params)

optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4) #ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
#torch.optimì€ ê²½ì‚¬í•˜ê°•ë²•ì¸ SGDë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ. ì—¬ê¸°ì„œëŠ” ìµœì í™”í•¨ìˆ˜ë¥¼ Adam ì´ìš©
#hyperparameter. optimization ì¡°ì ˆ íŒŒë¼ë¯¸í„° : epoch ìˆ˜, batch size, learning rateì¡´ì¬.
#lrì€ ì‘ì„ìˆ˜ë¡ í•™ìŠµì†ë„ ëŠë ¤ì§€ê³  ì»¤ì§€ë©´ ì˜ˆì¸¡ë¶ˆê°€ ë™ì‘ ë°œìƒ ã„±ã„´

lossfunc = torch.nn.CrossEntropyLoss() #ì†ì‹¤í•¨ìˆ˜ ì´ˆê¸°í™”
for epoch in range(MAXEPOCH):
    if epoch != MAXEPOCH-1:
        loss_t = []
        for i,(seq,SS) in enumerate(train_generator): #enumerate func : ì—¬ëŸ¬ ê°ì²´ë¥¼ ìˆ«ì ë§¤ê²¨ ì…€ ìˆ˜ ìˆë„ë¡ í•´ì¤Œ.
            optimizer.zero_grad()
            # get prediction
            # print(f'SSpred seq: {seq}')
            #if not SS: continue
            SSpred = model(seq.to(device))
            # calculate loss
            SS = SS.to(device)
            loss = lossfunc(SSpred,SS)
            loss.backward(retain_graph=True)
            optimizer.step()

            loss_t.append(loss.cpu().detach().numpy())
        #print("TRAIN:", epoch, float(np.mean(loss_)))
        
        loss_v = []
        for i,(seq,SS) in enumerate(valid_generator):
            # get prediction
            SSpred = model(seq.to(device))
            # calculate loss
            SS = SS.to(device)
            #print(f'what is SS: {SS}')
            #print(f'ss[0]: {SS[0]}')
            #print(f'what is SSpred: {SSpred}')
            #print(f'sspred[0]: {SSpred[0]}')
            loss = lossfunc(SSpred,SS)
            loss_v.append(loss.cpu().detach().numpy())

        def accuracy(predictions, labels):
            #ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µ ë¼ë²¨ì„ ë°›ì•„ì„œ accuracyë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜

            # ì˜ˆì¸¡ ê°’ ì¤‘ ê°€ì¥ í° ê°’ì„ ê°€ì§€ëŠ” indexë¥¼ ê°€ì ¸dhsek
            _, predicted = torch.max(predictions, 1)
            correct = (predicted == labels).sum().item()
            acc = correct / labels.size(0)
            return acc    
        
        print("Train/Valid: %3d %8.4f %8.4f"%(epoch, float(np.mean(loss_t)), float(np.mean(loss_v))))
        print("accuracy:", accuracy(SSpred,SS))
        #print("accuracy:", np.mean(accuracy))


'''
        accuracy = []    #ì •í™•ë„ëŠ” tp/
        for i,(seq,SS) in enumerate(valid_generator):
            # get prediction
            SSpred = model(seq.to(device))
            SS = SS.to(device)
            maxidx = torch.argmax(SSpred,dim=0)

    
            #big = []
            #for j in range(SS[0][1]):
               # big.append(max([SSpred[0][0][j],SSpred[0][1][j],SSpred[0][2][j]]))
            #big = torch.tensor(big)
            #print(f'before c ğŸ¤©: {big}, {SS}')
            #c = big==SS[0]
            #accuracy.append(len(SS[0][c])/len(SS[0][1]))         
              
     
def accuracy(predictions, labels):
    #ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µ ë¼ë²¨ì„ ë°›ì•„ì„œ accuracyë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜

    # ì˜ˆì¸¡ ê°’ ì¤‘ ê°€ì¥ í° ê°’ì„ ê°€ì§€ëŠ” indexë¥¼ ê°€ì ¸dhsek
    _, predicted = torch.max(predictions, 1)
    correct = (predicted == labels).sum().item()
    acc = correct / labels.size(0)
    return acc    '
       
'''
 
