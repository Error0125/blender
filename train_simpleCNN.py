import torch
device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
#import models
import numpy as np
import os
#os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID" 
#os.environ["CUDA_VISIBLE_DEVICES"]= "3"
import matplotlib.pyplot as plt

#model
import torch.nn as nn

MAXEPOCH=1
BATCH=1

class CNN2(nn.Module):
    def __init__(self, nlayer=4, dropout=0.1): 
        super().__init__()
        layers = []

        drop = torch.nn.Dropout(p=dropout)
        conv1 = torch.nn.Conv1d(20,32,3,padding=1) # aa1hot,channel,
        layers = [drop,conv1]

        for k in range(nlayer):
            conv2 = torch.nn.Conv1d(32,32,3,padding=1) # aa1hot,channel,
            layers.append(conv2)
            layers.append(nn.BatchNorm1d(32)) #reluë³´ë‹¤ ë” ì¢‹ì€ê²Œ ì •ê·œí™”í•˜ëŠ” ê²ƒ. ì •ê·œí™”í•œ ê°’ì„ í™œì„±í•¨ìˆ˜ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë„£ê³ , ìµœì¢… ì¶œë ¥ê°’ì„ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë„£ëŠ”ë‹¤. ìì„¸í•œê±´ ë©”ëª¨ì¥
            layers.append(nn.ReLU(inplace=True)) #í™œì„±í™” í•¨ìˆ˜. max(0,input) (linear                                    ë³€í™˜ í›„ ë¹„ì„ í˜•ì„± ë„ì…í•´ì„œ ì‹ ê²½ë§ ë³µì¡ì„±                                     ì¶”ê°€.
                                                 #inplace : ë”ì´ìƒ ì¶”ê°€ ë©”ëª¨ë¦¬ ì†Œë¹„í•˜
                                                 #ì§€ ì•Šê³  ëŒë¦¬ê¸°
                                                 #gradient vanishing/exploding
                                                 #ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ 1

        self.layers = nn.ModuleList(layers)#íŒŒì´í† ì¹˜ì—ê²Œ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“ˆì´ ì €ì¥ë˜ì–´ìˆìŒì„ ì•Œë ¤ì£¼ê¸° ìœ„í•´ nn.modulistë¡œ ë‹¤ì‹œ ë˜í•‘í•´ì£¼ëŠ” ê³¼ì •.
        # 1 x 32 x nres
        self.outlayer = nn.Linear(32,3)

    def forward(self, seq):
        #pred = seq # should B x 20 x nres
        for layer in self.layers:
            seq = layer(seq)

        seq = torch.transpose(seq,1,2) # put channel at the last

        pred = self.outlayer(seq)
        pred = torch.transpose(pred,2,1)
        #print(pred.size())
        return pred

class DataSet(torch.utils.data.Dataset): #ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹. ë°˜ë“œì‹œ 3ê°€ì§€ í¬í•¨í• ê²ƒ!
    def __init__(self, datalist):
        super().__init__()
        self.tags = datalist

    def __len__(self):
        return len(self.tags) #ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜

    def __getitem__(self,index): #ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°ì´í„°ì…‹ì—ì„œ ë¶ˆëŸ¬ì˜¤ê³  ë³€í˜•ê±°ì³ ë°˜í™˜.
        npz = '/Users/oyujeong/Desktop/2023 2á„’á…¡á†¨á„€á…µ/ps4-dataset/sss_struct/'+ self.tags[index]
        
        data = np.load(npz,allow_pickle=True) #trueë¡œ ì•ˆí•´ì£¼ë©´ íŒŒì¼ì´ ë¡œë“œ ì•ˆë  ìˆ˜ë„ ìˆìŒ.

        aas = 'ACDEFGHIKLMNPQRSTVWY' 
        SS3 = 'HEC'

        #print('ğŸ˜‹hello')

        seqs = [aas.index(a) for a in data['seq'].tolist()]
        #print(f'seqs: {seqs}')
        SSs  = [SS3.index(a) for a in data['SS'].tolist()]
        #print(f'SSs: {SSs}')
        seq1hot = np.transpose(np.eye(20)[seqs],(1,0)) # 20xnres
        #SS1hot = np.transpose(np.eye(3)[SSs],(1,0))
        #print('!!!!!!!!!!')
        #print(seq1hot.shape[1])

    

        return seq1hot, SSs, seq1hot.shape[1]

def collate(samples):
    try:
        seq,SS,nres = map(list, zip(*samples))
        #print(f'what is seq: {seq}')
        #print(f'what is SS: {SS}')
        nres = max(nres)
        #print(f'maxnres: {nres}')
        B = len(seq)
        #print(f'b: {B}')

        # map into maxres
        seqs = torch.zeros(B,20,nres)
        SSs  = torch.zeros(B,nres,dtype=torch.long)
        for i,s in enumerate(seq):
            #print(f'seqs: {seqs}')
            #print(seqs[i,:,:len(s[1])]
            seqs[i,:,:len(s[1])] = torch.tensor(s)
        for i,s in enumerate(SS):
            #print(f'SSs: {SSs}')
            #print(f'ss[i]: {SS[i]}')
            #print(f'ss[i][:3]: {SS[i][:3]}')
            SSs[i][:len(s)] = torch.tensor(s)

        #print(f'seqs: {seqs}')
        #print(f'SSs: {SSs}')

    except:
        print("collate fail")
        return False, False

    return seqs, SSs

model = CNN2()
model.to(device) #cnn ëª¨ë¸ì„ gpuë¡œ ì´ë™.

## load dataset
trainlist = np.load('/Users/oyujeong/Desktop/2023 2á„’á…¡á†¨á„€á…µ/ps4-dataset/train.npy')
validlist = np.load('/Users/oyujeong/Desktop/2023 2á„’á…¡á†¨á„€á…µ/ps4-dataset/valid.npy')

trainset = DataSet(trainlist)
validset = DataSet(validlist)

generator_params = {
    'shuffle': False, #ëª¨ë“  ë°°ì¹˜ ìˆœíšŒ í›„ ë°ì´í„°ì…‹ì˜ ì…”í”Œ ì—¬ë¶€
    'num_workers': 0, #ì°¸ì—¬ì‹œí‚¬ cpu ì½”ì–´ ê°œìˆ˜. (multi-loader, íŠœë‹ì„ í†µí•´ ì†ë„ê°€ ìµœëŒ€í•œ
                      #ì•ˆëŠë ¤ì§€ëŠ” ì„ ì—ì„œ ì¡°ì ˆ ê°€ëŠ¥. default = 0)
    'pin_memory': True, #íŠ¸ë£¨ì˜ ê²½ìš°, í…ì„œë¥¼ cuda ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼. ì¦‰, cpuì—ì„œ ëŒì•„ê°€ë˜ ë°ì´í„°ì…‹ì„
                        #gpuë¡œ ì˜®ê²¨ì„œ ê³„ì‚°ì„ ì§„í–‰í•˜ë„ë¡ í•œë‹¤.
    'collate_fn': collate, #ë°ì´í„° ì‚¬ì´ì¦ˆë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì‚¬ìš©.?
    'batch_size': BATCH,
    'worker_init_fn' : np.random.seed() #ì–´ë–¤ workerë¥¼ ë¶ˆëŸ¬ì˜¬ê²ƒì¸ê°€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
                                        #np.random.seed()ëŠ” ê´„í˜¸ì•ˆì˜ ìˆ«ìë¥¼ ì‹œì‘ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‚œìˆ˜ë¥¼ í˜•ì„±í•˜ëŠ” ê²ƒ. ì‹œì‘ ìˆ«ìë¥¼ ê³ ì •í•œë‹¤!
                                            #ê³ ì • ìˆ«ìê°€ ë™ì¼í•˜ë©´ ìƒì„±ë˜ëŠ” ë‚œìˆ˜ë„ ë™ì¼í•¨. (íŒ¨í„´ì´ ë™ì¼í•˜ë‹ˆê¹Œ)
}
train_generator = torch.utils.data.DataLoader(trainset, **generator_params)
valid_generator = torch.utils.data.DataLoader(validset, **generator_params)

optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4) #ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
#torch.optimì€ ê²½ì‚¬í•˜ê°•ë²•ì¸ SGDë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ. ì—¬ê¸°ì„œëŠ” ìµœì í™”í•¨ìˆ˜ë¥¼ Adam ì´ìš©
#hyperparameter. optimization ì¡°ì ˆ íŒŒë¼ë¯¸í„° : epoch ìˆ˜, batch size, learning rateì¡´ì¬.
#lrì€ ì‘ì„ìˆ˜ë¡ í•™ìŠµì†ë„ ëŠë ¤ì§€ê³  ì»¤ì§€ë©´ ì˜ˆì¸¡ë¶ˆê°€ ë™ì‘ ë°œìƒ ã„±ã„´

valid_accuracies = [] 
train_losses = []
valid_losses = []

lossfunc = torch.nn.CrossEntropyLoss() #ì†ì‹¤í•¨ìˆ˜ ì´ˆê¸°í™”
for epoch in range(MAXEPOCH):
    if epoch != MAXEPOCH-1:
        loss_t = []
        for i,(seq,SS) in enumerate(train_generator): #enumerate func : ì—¬ëŸ¬ ê°ì²´ë¥¼ ìˆ«ì ë§¤ê²¨ ì…€ ìˆ˜ ìˆë„ë¡ í•´ì¤Œ.
            optimizer.zero_grad()
            # get prediction
            #print(f'SSpred seq: {seq.size(2)}')
            if seq.size(2) < 15: continue
            #if not SS: continue
            SSpred = model(seq.to(device))
            # calculate loss
            SS = SS.to(device)
            loss = lossfunc(SSpred,SS)
            loss.backward(retain_graph=True)
            optimizer.step()

            loss_t.append(loss.cpu().detach().numpy())
        #print("TRAIN:", epoch, float(np.mean(loss_)))
        
        loss_v = []
        for i,(seq,SS) in enumerate(valid_generator):
            # get prediction
            if seq.size(2) < 15: continue
            SSpred = model(seq.to(device))
            # calculate loss
            SS = SS.to(device)
            #print(f'what is SS: {SS}')
            #print(f'ss[0]: {SS[0]}')
            #print(f'what is SSpred: {SSpred}')
            #print(f'sspred[0]: {SSpred[0]}')
            loss = lossfunc(SSpred,SS)
            loss_v.append(loss.cpu().detach().numpy())

        accuracy = []  # List to store accuracy for each batch
        for i, (seq, SS) in enumerate(valid_generator):
            # get prediction
            if seq.size(2) < 15: continue
            SSpred = model(seq.to(device))
            SS = SS.to(device)

            # Calculate accuracy for each batch
            _, predicted = torch.max(SSpred, 1)  # Find the index of the maximum value along the last dimension
            acc = torch.sum(predicted == SS).item() / (SS.size(1))  # Compute accuracy for the batch
            accuracy.append(acc)  # Append accuracy for the batch to the list

        # Compute average accuracy for the epoch and append it to the list of validation accuracies

        train_loss = float(np.mean(loss_t))
        valid_loss = float(np.mean(loss_v))
        avg_accuracy = np.mean(accuracy)

        valid_accuracies.append(avg_accuracy)
        train_losses.append(train_loss)
        valid_losses.append(valid_loss)
        
        
       

        print("Train/Valid: %3d %8.4f %8.4f" % (epoch, train_loss, valid_loss))
        print("accuracy:", avg_accuracy)


model_info = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'train_losses': train_losses,
    'valid_losses': valid_losses,
    'valid_accuracies': valid_accuracies
}

# Define the file path to save the model
model_save_path = '/Users/oyujeong/Desktop/2023 2á„’á…¡á†¨á„€á…µ/ps4-dataset/save/mymodel.pth'  # Change this path to your desired location and filename

# Save the model
torch.save(model_info, model_save_path)



# Plotting Loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(valid_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

# Plotting Accuracy
plt.figure(figsize=(10, 5))
plt.plot(valid_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Validation Accuracy')
plt.show()

